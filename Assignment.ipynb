{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import pandas as pd\n",
    "\n",
    "def pgconnect():\n",
    "    YOUR_UNIKEY = 'zjia5829'\n",
    "    YOUR_PW     = '470343256'\n",
    "    DB_LOGIN    = 'y20s1d2x01_'+YOUR_UNIKEY\n",
    "\n",
    "    try:\n",
    "        db = create_engine('postgres+psycopg2://'+DB_LOGIN+':'+YOUR_PW+'@soitpw11d59.shared.sydney.edu.au/'+DB_LOGIN, echo=False)\n",
    "        conn = db.connect()\n",
    "        print('connected')\n",
    "    except Exception as e:\n",
    "        print(\"unable to connect to the database\")\n",
    "        print(e)\n",
    "    return db,conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n"
     ]
    }
   ],
   "source": [
    "db,conn = pgconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table StatisticalAreas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists StatisticalAreas;\")\n",
    "\n",
    "statistical_areas = \"\"\"\n",
    "create table StatisticalAreas(\n",
    "    area_id varchar(50) primary key,\n",
    "    area_name varchar(50),\n",
    "    parent_area_id varchar(50)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(statistical_areas)\n",
    "\n",
    "sa_data = pd.read_csv('StatisticalAreas.csv')\n",
    "sa_data.columns = ['area_id','area_name','parent_area_id']\n",
    "table_name = \"statisticalareas\"\n",
    "sa_data.to_sql(table_name, con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists Neighbourhoods;\")\n",
    "\n",
    "neighbourhoods = \"\"\"\n",
    "create table Neighbourhoods(\n",
    "    area_id varchar(50) primary key,\n",
    "    area_name varchar(50),\n",
    "    land_area double precision,\n",
    "    population integer,\n",
    "    dwellings integer,\n",
    "    businesses integer,\n",
    "    median_income integer,\n",
    "    avg_monthly_rent integer\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(neighbourhoods)\n",
    "\n",
    "nh_data = pd.read_csv('Neighbourhoods.csv')\n",
    "nh_data.columns = ['area_id','area_name','land_area','population','dwellings','businesses','median_income','avg_monthly_rent']\n",
    "table_name = \"neighbourhoods\"\n",
    "nh_data.to_sql(table_name, con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table PopulationStats2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists PopulationStats2016;\")\n",
    "\n",
    "populationstats2016 = \"\"\"\n",
    "create table PopulationStats2016(\n",
    "    area_id varchar(50),\n",
    "    area_name varchar(50),\n",
    "    age_0_4 integer,\n",
    "    age_5_9 integer,\n",
    "    age_10_14 integer,\n",
    "    age_15_19 integer,\n",
    "    age_20_24 integer,\n",
    "    age_25_29 integer,\n",
    "    age_30_34 integer,\n",
    "    age_35_39 integer,\n",
    "    age_40_44 integer,\n",
    "    age_45_49 integer,\n",
    "    age_50_54 integer,\n",
    "    age_55_59 integer,\n",
    "    age_60_64 integer,\n",
    "    age_65_69 integer,\n",
    "    age_70_74 integer,\n",
    "    age_75_79 integer,\n",
    "    age_80_84 integer,\n",
    "    age_85_and_over integer,\n",
    "    total_persons integer,\n",
    "    females integer,\n",
    "    males integer\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(populationstats2016)\n",
    "\n",
    "ps_data = pd.read_csv('PopulationStats2016.csv')\n",
    "ps_data.columns = ['area_id', 'area_name', 'age_0_4', 'age_5_9', 'age_10_14', 'age_15_19', 'age_20_24', 'age_25_29', 'age_30_34', 'age_35_39', 'age_40_44', 'age_45_49', 'age_50_54', 'age_55_59', 'age_60_64', 'age_65_69', 'age_70_74', 'age_75_79', 'age_80_84', 'age_85_and_over', 'total_persons', 'females', 'males']\n",
    "table_name = \"populationstats2016\"\n",
    "ps_data.to_sql(table_name, con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table HealthServices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists HealthServices;\")\n",
    "\n",
    "healthservices = \"\"\"\n",
    "create table HealthServices(\n",
    "    id varchar(50) primary key,\n",
    "    name varchar(100),\n",
    "    category varchar(50),\n",
    "    num_beds double precision,\n",
    "    address varchar(100),\n",
    "    suburb varchar(50),\n",
    "    state varchar(50),\n",
    "    postcode varchar(50),\n",
    "    longitude float,\n",
    "    latitude float,\n",
    "    comment text,\n",
    "    website text\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(healthservices)\n",
    "\n",
    "hs_data = pd.read_csv('HealthServices.csv')\n",
    "hs_data.columns = ['id', 'name', 'category', 'num_beds', 'address', 'suburb', 'state', 'postcode', 'longitude', 'latitude', 'comment', 'website']\n",
    "table_name = \"healthservices\"\n",
    "hs_data.to_sql(table_name, con=conn, if_exists='append', index=False)\n",
    "\n",
    "conn.execute(\"alter table healthservices add location GEOMETRY(Point,4326);\")\n",
    "conn.execute(\"update healthservices set location = ST_SetSRID(ST_MakePoint(longitude,latitude),4326);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table NSW_Postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x11836bef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(\"drop table if exists NSW_Postcodes;\")\n",
    "\n",
    "nsw_postcodes = \"\"\"\n",
    "create table NSW_Postcodes(\n",
    "    id varchar(50) primary key,\n",
    "    postcode varchar(50),\n",
    "    locality varchar(50),\n",
    "    longitude float,\n",
    "    latitude float\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(nsw_postcodes)\n",
    "\n",
    "np_data = pd.read_csv('NSW_Postcodes.csv')\n",
    "np_data.columns = ['id', 'postcode', 'locality','longitude', 'latitude']\n",
    "table_name = \"nsw_postcodes\"\n",
    "np_data.to_sql(table_name, con=conn, if_exists='append', index=False)\n",
    "\n",
    "conn.execute(\"alter table NSW_Postcodes add location GEOMETRY(Point,4326);\")\n",
    "conn.execute(\"update NSW_Postcodes set location = ST_SetSRID(ST_MakePoint(longitude,latitude),4326);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table COVID19_Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists COVID19_Statistics;\")\n",
    "\n",
    "covid19_statistics = \"\"\"\n",
    "create table COVID19_Statistics(\n",
    "    site_id varchar(50) primary key,\n",
    "    Centre_name varchar(100),\n",
    "    Phone_number varchar(100),\n",
    "    Opening_hours varchar(100),\n",
    "    longitude float,\n",
    "    latitude float,\n",
    "    test_capacity integer\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(covid19_statistics)\n",
    "\n",
    "c19_data = pd.read_csv('covid19_nsw_testsites_simulated_capacity.csv')\n",
    "c19_data.columns = ['site_id', 'centre_name', 'phone_number', 'opening_hours','longitude', 'latitude', 'test_capacity']\n",
    "table_name = \"covid19_statistics\"\n",
    "c19_data.to_sql(table_name, con=conn, if_exists='append', index=False)\n",
    "\n",
    "conn.execute(\"alter table covid19_statistics add location GEOMETRY(Point,4326);\")\n",
    "conn.execute(\"update covid19_statistics set location = ST_SetSRID(ST_MakePoint(longitude,latitude),4326);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Sydney_Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists Sydney_Neighbourhoods;\")\n",
    "\n",
    "Sydney_neighbourhood = \"\"\"\n",
    "CREATE TABLE Sydney_Neighbourhoods(\n",
    "    area_id varchar(50) primary key,\n",
    "    area_name varchar(50),\n",
    "    land_area double precision,\n",
    "    population integer,\n",
    "    dwellings integer,\n",
    "    businesses integer,\n",
    "    median_income integer,\n",
    "    avg_monthly_rent integer);\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(Sydney_neighbourhood)\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "    INSERT INTO Sydney_Neighbourhoods \n",
    "    SELECT * FROM Neighbourhoods WHERE area_id IN (\n",
    "            SELECT area_id FROM StatisticalAreas WHERE parent_area_id IN (\n",
    "            SELECT area_id FROM StatisticalAreas WHERE parent_area_id IN (\n",
    "            SELECT area_id FROM StatisticalAreas WHERE parent_area_id = '10')));\n",
    "\"\"\")\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Census_data_From_Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists Census_data_Neighbourhoods;\")\n",
    "\n",
    "Census_data_Neighbourhoods = \"\"\"\n",
    "create table Census_data_Neighbourhoods(\n",
    "    area_id varchar(50) primary key,\n",
    "    area_name varchar(50),\n",
    "    population integer,\n",
    "    age_0_4 integer,\n",
    "    age_5_9 integer,\n",
    "    age_10_14 integer,\n",
    "    age_15_19 integer,\n",
    "    age_20_24 integer,\n",
    "    age_25_29 integer,\n",
    "    age_30_34 integer,\n",
    "    age_35_39 integer,\n",
    "    age_40_44 integer,\n",
    "    age_45_49 integer,\n",
    "    age_50_54 integer,\n",
    "    age_55_59 integer,\n",
    "    age_60_64 integer,\n",
    "    age_65_69 integer,\n",
    "    age_70_74 integer,\n",
    "    age_75_79 integer,\n",
    "    age_80_84 integer,\n",
    "    age_85_and_over integer);\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(Census_data_Neighbourhoods)\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "    INSERT INTO Census_data_Neighbourhoods \n",
    "    SELECT n.area_id, n.area_name, population, \n",
    "    age_0_4, age_5_9, age_10_14, age_15_19, age_20_24, \n",
    "    age_25_29, age_30_34, age_35_39, age_40_44, age_45_49, \n",
    "    age_50_54, age_55_59, age_60_64, age_65_69, age_70_74, \n",
    "    age_75_79, age_80_84, age_85_and_over \n",
    "    FROM Neighbourhoods n JOIN PopulationStats2016 USING (area_id);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Geometry data and Spatial Join with neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function)\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "\n",
    "data_path = \"./SA2_2016_aust_shape/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "areas = gpd.read_file( os.path.join(data_path, \"SA2_2016_AUST.shp\") )\n",
    "print(\"#cities: \", len(areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas.head().geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "def pgconnect(credential_filepath):\n",
    "    try:\n",
    "        with open(credential_filepath) as f:\n",
    "            db_conn_dict = json.load(f)\n",
    "        conn = psycopg2.connect(**db_conn_dict)\n",
    "        print('connected')\n",
    "    except Exception as e:\n",
    "        print(\"unable to connect to the database\")\n",
    "        print(e)\n",
    "        return None\n",
    "    return conn\n",
    "\n",
    "\n",
    "credfilepath = os.path.join(\"data2x01_db.json\")\n",
    "\n",
    "conn = pgconnect(credfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgquery( conn, sqlcmd, args=None, msg=False, returntype='tuple'):\n",
    "    \"\"\" utility function to execute some SQL query statement\n",
    "        it can take optional arguments (as a dictionary) to fill in for placeholders in the SQL\n",
    "        will return the complete query result as return value - or in case of error: None\n",
    "        error and transaction handling built-in (by using the 'wi=th' clauses)\"\"\"\n",
    "    retval = None\n",
    "    with conn:\n",
    "        cursortype = None if returntype != 'dict' else psycopg2.extras.RealDictCursor\n",
    "        with conn.cursor(cursor_factory = cursortype) as cur:\n",
    "            try:\n",
    "                if args is None:\n",
    "                    cur.execute(sqlcmd)\n",
    "                else:\n",
    "                    cur.execute(sqlcmd, args)\n",
    "                if (cur.description != None):\n",
    "                    retval = cur.fetchall()\n",
    "                if msg != False:\n",
    "                    print(\"success: \" + msg)\n",
    "            except psycopg2.DatabaseError as e:\n",
    "                if e.pgcode != None:\n",
    "                    if msg: print(\"db read error: \" + msg)\n",
    "                    print(e)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgis_check = '''\n",
    "SELECT PostGIS_Version();\n",
    "'''\n",
    "pgquery(conn,postgis_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_schema = '''CREATE TABLE sydney_table(\n",
    "                  SA2_mean varchar(200) primary key,\n",
    "                  SA2_id varchar(200) ,\n",
    "                  SA2_name varchar(200),\n",
    "                  SA3_id varchar(200),\n",
    "                  SA3_name varchar(200),\n",
    "                  SA4_id varchar(200),\n",
    "                  SA4_name varchar(200),\n",
    "                  GCC_id varchar(200),\n",
    "                  GCC_name varchar(200),\n",
    "                  STE_id varchar(200),\n",
    "                  STE_name varchar(200),\n",
    "                  areas float,\n",
    "                  geometry GEOMETRY(MULTIPOLYGON, 4326)\n",
    "                )''' \n",
    "\n",
    "pgquery(conn, \"DROP TABLE IF EXISTS sydney_table\", msg=\"cleared old table\")\n",
    "pgquery(conn, sydney_schema, msg=\"created sydney_table table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO sydney_table VALUES ( %(SA2_MAIN16)s, %(SA2_5DIG16)s, %(SA2_NAME16)s,%(SA3_CODE16)s,%(SA3_NAME16)s,%(SA4_CODE16)s,%(SA4_NAME16)s,%(GCC_CODE16)s,%(GCC_NAME16)s,%(STE_CODE16)s,%(STE_NAME16)s,%(AREASQKM16)s, \n",
    "                ST_Multi(ST_GeomFromText(%(geom_wkt)s, 4326)))\"\"\"\n",
    "\n",
    "# create a new column called 'geom_wkt' with the \"Well Known Text-Format (WKT)\" of each geometry; used by SQL insert\n",
    "areas['geom_wkt'] = areas['geometry'].apply(lambda x: x.wkt if x is not None else x)\n",
    "\n",
    "# insert all countries using above's SQL Insert statement into the database\n",
    "for idx, area in areas.iterrows():\n",
    "    pgquery(conn, insert_stmt, args=area, msg=\"inserted \"+str(area['SA2_NAME16']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT COUNT(*) FROM sydney_table\"\n",
    "result= pgquery(conn, query, returntype='dict')\n",
    "from pprint import pprint \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index on GIST(geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "index_command = \"CREATE INDEX areas_idx ON sydney_table USING GIST (geometry)\"\n",
    "result= pgquery(conn, index_command, returntype='dict')\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Table Destination_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the limit first!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "base_url = 'http://soit-app-pro-4.ucc.usyd.edu.au:3000/api/v1/json'\n",
    "\n",
    "my_params= {'data' :'origin, destinations','format':'json','limit':'1'}\n",
    "response = requests.get(base_url, params = my_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old table for load all the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conn.execute(\"drop table if exists commuters;\")\n",
    "\n",
    "commuters = \"\"\"\n",
    "create table commuters(\n",
    "    origin varchar(200),\n",
    "    destination varchar(200),\n",
    "    people integer\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(commuters)\n",
    "\n",
    "matches  = response.json()\n",
    "num_matches = len(matches)\n",
    "\n",
    "list = []\n",
    "for i in range(0,num_matches):\n",
    "    match_origin = matches[i]['origin']\n",
    "    match_destinations = matches[i]['destinations']\n",
    "    for j in range(0,len(match_destinations)):\n",
    "        match_destination = match_destinations[j]['destination']\n",
    "        match_people = match_destinations[j]['people']\n",
    "        list.append([match_origin,match_destination,match_people])\n",
    "            \n",
    "df = pd.DataFrame (list)\n",
    "df.columns = ['origin','destination','people']\n",
    "table_name = \"commuters\"\n",
    "df.to_sql(table_name, con=conn, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra table of commuters to refine scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists commuters;\")\n",
    "\n",
    "commuters = \"\"\"\n",
    "create table commuters(\n",
    "    origin varchar(200) primary key,\n",
    "    sum_people integer\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(commuters)\n",
    "\n",
    "matches  = response.json()\n",
    "num_matches = len(matches)\n",
    "\n",
    "list = []\n",
    "for i in range(0,num_matches):\n",
    "    match_origin = matches[i]['origin']\n",
    "    match_destinations = matches[i]['destinations']\n",
    "    sum_people = 0\n",
    "    for j in range(0,len(match_destinations)):\n",
    "        sum_people += match_destinations[j]['people']\n",
    "    list.append([match_origin,sum_people])\n",
    "            \n",
    "df = pd.DataFrame (list)\n",
    "df.columns = ['origin','sum_people']\n",
    "table_name = \"commuters\"\n",
    "df.to_sql(table_name, con=conn, if_exists='append', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Compute scores and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table('viral_vulnerability_sydney',conn, \n",
    "        columns=['area_id','population_density','population_age','healthservice_density','hospitalbed_density','sum_people'])\n",
    "# df = df.to_numpy().transpose()\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(df):\n",
    "    df.columns = [x + \"_zscore\" for x in df.columns.tolist()]\n",
    "    return (df - df.mean())/df.std(ddof=0)\n",
    "all_z_scores = z_score(df.iloc[:, [False, True, True, True, True, True]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def normalize(data):\n",
    "    result = []\n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    for val in data:\n",
    "        normalized_score =(val-min_val) * 100 / (max_val - min_val)\n",
    "        result.append(round(normalized_score))\n",
    "    return result\n",
    "\n",
    "# compute sum for each neighbourhood row to get the sum of z_scores\n",
    "row_sum_of_z_scores = all_z_scores['population_density_zscore'] + all_z_scores['population_age_zscore']\\\n",
    "                      - all_z_scores['healthservice_density_zscore'] - all_z_scores['hospitalbed_density_zscore']\\\n",
    "                        + all_z_scores['sum_people_zscore']\n",
    "\n",
    "\n",
    "# compute vulnerability for each neighbourhood\n",
    "vulnerability = []\n",
    "for i in row_sum_of_z_scores:\n",
    "    vulnerability.append(sigmoid(i))\n",
    "scores = normalize(vulnerability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df['area_id']\n",
    "# test = df['sum_test_capacity']\n",
    "# final_data = list(zip(ids,test,scores))\n",
    "final_data = list(zip(ids,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name=['area_id','tests','score']\n",
    "name=['area_id','score']\n",
    "csvdf=pd.DataFrame(columns=name,data=final_data)\n",
    "csvdf.to_csv('./result.csv',encoding='gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table for final viral_vulnerability_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists viral_vulnerability_score;\")\n",
    "\n",
    "viral_vulnerability_score = \"\"\"\n",
    "create table viral_vulnerability_score(\n",
    "    area_id varchar(50) primary key,\n",
    "    score float\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(viral_vulnerability_score)\n",
    "\n",
    "score_data = pd.read_csv('result.csv')\n",
    "score_data = score_data.iloc[:, [False, True, True]]\n",
    "table_name = \"viral_vulnerability_score\"\n",
    "score_data.to_sql(table_name, con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table for postcode_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"drop table if exists postcode_cases;\")\n",
    "\n",
    "postcode_cases = \"\"\"\n",
    "create table postcode_cases(\n",
    "    postcode varchar(50),\n",
    "    cases integer\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(postcode_cases)\n",
    "\n",
    "cases_data = pd.read_csv('postcode_cases.csv')\n",
    "cases_data = cases_data.iloc[:, [False,True,True]]\n",
    "table_name = \"postcode_cases\"\n",
    "cases_data.to_sql(table_name, con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table viral_vulnerability_sydney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1186cc7f0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(\"drop table if exists viral_vulnerability_sydney;\")\n",
    "\n",
    "viral_vulnerability_sydney = \"\"\"\n",
    "create table viral_vulnerability_sydney(\n",
    "    area_id varchar(50) primary key,\n",
    "    area_name varchar(50),\n",
    "    population_density float,\n",
    "    population_age float,\n",
    "    healthservice_density float,\n",
    "    hospitalbed_density float,\n",
    "    sum_test_capacity integer,\n",
    "    sum_people float,\n",
    "    score float,\n",
    "    cases integer,\n",
    "    geometry GEOMETRY(MULTIPOLYGON, 4326)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(viral_vulnerability_sydney)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multicolumn Index for final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "index_multicolumn = \"CREATE INDEX area_name_and_score ON viral_vulnerability_sydney (area_name,score);\"\n",
    "result= pgquery(conn, index_multicolumn, returntype='dict')\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL TABLE WITH DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x118250908>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(\"\"\"\n",
    "       INSERT INTO viral_vulnerability_sydney\n",
    "       SELECT sn.area_id, sn.area_name,\n",
    "       COALESCE(population*1.0/land_area,0) AS \"population_density\",\n",
    "       COALESCE((age_70_74 + age_75_79 + age_80_84 + age_85_and_over)*1.0/population,0) AS \"population_age\",\n",
    "       COALESCE(COUNT(DISTINCT h.id)*1.0/population*1000,0) AS \"healthservice_density\",\n",
    "       COALESCE(SUM(COALESCE(h.num_beds,0))*1.0/population*1000.0,0) AS \"hospitalbed_density\",\n",
    "       SUM(COALESCE(test_capacity,0)) AS \"sum_test_capacity\",\n",
    "       COALESCE(cm.sum_people*1.0/population*1000.0,0) AS \"sum_people\",\n",
    "       sco.score,\n",
    "       MAX(COALESCE(cases,0)) AS \"cases\",\n",
    "       st.geometry \n",
    "       FROM sydney_table st JOIN sydney_neighbourhoods sn ON st.SA2_mean = sn.area_id\n",
    "                                        JOIN PopulationStats2016 USING(area_id)\n",
    "                                        LEFT JOIN healthservices h ON (ST_Contains(st.geometry, h.location))\n",
    "                                        LEFT JOIN covid19_statistics cs  ON (ST_Contains(st.geometry, cs.location))\n",
    "                                        LEFT JOIN commuters cm ON sn.area_id = cm.origin\n",
    "                                        LEFT JOIN viral_vulnerability_score sco USING(area_id)\n",
    "                                        LEFT JOIN (SELECT postcode,cases,location\n",
    "                                                   FROM postcode_cases RIGHT JOIN\n",
    "                                                  (SELECT DISTINCT postcode,location\n",
    "                                                   FROM nsw_postcodes) AS postcode_dis USING(postcode))\n",
    "                                                   AS post_cases ON (ST_Contains(st.geometry, post_cases.location)) \n",
    "       GROUP BY sn.area_id,population_age,st.geometry,cm.origin,sco.area_id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final version table to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_sql_table('viral_vulnerability_sydney',conn)\n",
    "final_data.to_csv('./final_table.csv',encoding='gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "db.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
